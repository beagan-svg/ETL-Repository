{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079ad6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pprint\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import json\n",
    "import bs4 as bs\n",
    "import h5py as h5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1745b8",
   "metadata": {},
   "source": [
    "### Read Resource TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db92db16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Resource TSV\n",
    "open_resource = open(\"resource.tsv\", \"r\")\n",
    "header = open_resource.readline()\n",
    "example = open_resource.readline()\n",
    "\n",
    "# Key = ID, Value = Resource Name\n",
    "resource_dict = dict()\n",
    "for row in open_resource:\n",
    "    split_row =  row.split(\"\\t\")\n",
    "    \n",
    "    if '\\n' == split_row[len(split_row)-1]:\n",
    "        split_row[len(split_row)-1] = \"NULL\"\n",
    "        \n",
    "    resource_id = split_row[2]\n",
    "    resource_name = split_row[0]\n",
    "    \n",
    "    count = 2\n",
    "    field_list = list()\n",
    "    while 1 < count < 11:\n",
    "        if split_row[count] != '':\n",
    "            field_value = split_row[count]\n",
    "            field_value = field_value.rstrip()\n",
    "            if '\"' in field_value:\n",
    "                field_value = field_value.replace('\"', '')\n",
    "            field_list.append(field_value)\n",
    "        else:\n",
    "            field_list.append(\"NULL\")\n",
    "        count += 1\n",
    "    \n",
    "    resource_dict[resource_id] = field_list\n",
    "\n",
    "pprint.pprint(resource_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939563a5",
   "metadata": {},
   "source": [
    "### Read Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefe6131",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"schema.txt\", \"r\")\n",
    "\n",
    "schema_dict = dict()\n",
    "name = ''\n",
    "table_dict = dict()\n",
    "count = False\n",
    "\n",
    "for row in f:\n",
    "    row = row.rstrip()\n",
    "    if \"---\" == row:\n",
    "        count = True\n",
    "        continue\n",
    "    \n",
    "    if count == True:\n",
    "        row_list = row.split(\"`\")\n",
    "        name = row_list[1]\n",
    "        schema_dict[name] = list()\n",
    "        schema_dict[name].append(row)\n",
    "        \n",
    "        table_dict[name] = list()\n",
    "        count = False\n",
    "    \n",
    "    else:\n",
    "        schema_dict[name].append(row)\n",
    "        if row[:3] == ' `':\n",
    "            row = row.split('`')[1]\n",
    "            row = {row:list()}\n",
    "            table_dict[name].append(row)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d3bfcc",
   "metadata": {},
   "source": [
    "### Show Schema Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054ba19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(schema_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f3f28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printSchema(table_name, open_sql):\n",
    "    if table_name == \"begin\":\n",
    "        count = 0\n",
    "        for row in schema_dict[table_name]:\n",
    "            if count == 0:\n",
    "                count += 1\n",
    "                continue\n",
    "            else:\n",
    "                open_sql.write(\"\\n{}\".format(str(row)))\n",
    "    else:\n",
    "        for row in schema_dict[table_name]:\n",
    "            open_sql.write(\"\\n{}\".format(str(row)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88050f64",
   "metadata": {},
   "source": [
    "### Write beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dd2cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to master_sql\n",
    "open_sql = open(\"master.sql\", \"w\")\n",
    "printSchema('begin', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fa91df",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab36a566",
   "metadata": {},
   "source": [
    "### Write Resource Schema Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b31c008",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('resource', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd30947",
   "metadata": {},
   "source": [
    "### Insert values Resource into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb584a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beginInsert(table_name):\n",
    "    open_sql.write('\\n\\nLOCK TABLES `{}` WRITE;'.format(table_name))\n",
    "    open_sql.write('\\nINSERT INTO `{}` VALUES'.format(table_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14255467",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginInsert('resource')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d44aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillTable(resource_dict, open_sql):\n",
    "    index = 0\n",
    "    for key, value in resource_dict.items():\n",
    "        if index == len(resource_dict.keys())-1:\n",
    "            open_sql.write('\\n(')\n",
    "            for count, entry in enumerate(value):\n",
    "                entry = str(entry)\n",
    "                if count == len(value)-1:\n",
    "                    entry = entry.rstrip()\n",
    "                    if entry == \" \" or entry == \"\":\n",
    "                        open_sql.write(\"{});\".format(\"NULL\"))\n",
    "                    elif entry.isnumeric():\n",
    "                        open_sql.write(\"{});\".format(entry))\n",
    "                    elif \"NULL\" == entry or \"Null\" == entry:\n",
    "                        open_sql.write(\"{});\".format(entry))\n",
    "                    else:\n",
    "                        open_sql.write('\"{}\");'.format(entry))\n",
    "                else:\n",
    "                    if entry == \" \" or entry == \"\":\n",
    "                        open_sql.write(\"{},\".format(\"NULL\"))\n",
    "                    elif entry.isnumeric():\n",
    "                        open_sql.write(\"{},\".format(entry))\n",
    "                    elif \"NULL\" == entry:\n",
    "                        open_sql.write(\"{},\".format(entry))\n",
    "                    else:\n",
    "                        open_sql.write('\"{}\",'.format(entry))\n",
    "            break\n",
    "            \n",
    "        open_sql.write('\\n(')   \n",
    "        for count, entry in enumerate(value):\n",
    "            entry = str(entry)\n",
    "            if count == len(value)-1:\n",
    "                entry = entry.rstrip()\n",
    "                if entry == \" \" or entry == \"\":\n",
    "                    open_sql.write(\"{}),\".format(\"NULL\"))\n",
    "                elif entry.isnumeric():\n",
    "                    open_sql.write(\"{}),\".format(entry))\n",
    "                elif \"NULL\" == entry or \"Null\" == entry:\n",
    "                    open_sql.write(\"{}),\".format(entry))\n",
    "                else:\n",
    "                    open_sql.write('\"{}\"),'.format(entry))\n",
    "            else:\n",
    "                if entry == \" \" or entry == \"\":\n",
    "                    open_sql.write(\"{},\".format(\"NULL\"))\n",
    "                elif entry.isnumeric():\n",
    "                    open_sql.write(\"{},\".format(entry))\n",
    "                elif \"NULL\" == entry:\n",
    "                    open_sql.write(\"{},\".format(entry))\n",
    "                else:\n",
    "                    open_sql.write('\"{}\",'.format(entry))\n",
    "        index += 1\n",
    "        \n",
    "    open_sql.write(\"\\nUNLOCK TABLES;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959e086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fillTable(resource_dict, open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4196e8c",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2f5b55",
   "metadata": {},
   "source": [
    "### Read Publications TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52618e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Publication TSV\n",
    "open_publication = open(\"publications.tsv\", \"r\")\n",
    "\n",
    "# Read Header\n",
    "header = open_publication.readline()\n",
    "# Read Example\n",
    "example = open_publication.readline()\n",
    "\n",
    "# Key = ID, Value = Publications Name\n",
    "publication_dict = dict()\n",
    "for row in open_publication:\n",
    "    split_row =  row.split(\"\\t\")\n",
    "    \n",
    "    if split_row[1] == '':\n",
    "        continue\n",
    "    \n",
    "    if '\\n' in split_row[len(split_row)-1]:\n",
    "        split_row[len(split_row)-1] = split_row[len(split_row)-1].rstrip()\n",
    "        \n",
    "    publication_id = split_row[0]\n",
    "    \n",
    "    count = 0\n",
    "    field_list = list()\n",
    "    while count < 17:\n",
    "        if split_row[count] != '':\n",
    "            field_value = split_row[count]\n",
    "            if '\"' in field_value:\n",
    "                field_value = field_value.replace('\"', '')\n",
    "            field_list.append(field_value)\n",
    "        else:\n",
    "            field_list.append(\"Null\")\n",
    "        count += 1\n",
    "    \n",
    "    publication_dict[publication_id] = field_list\n",
    "\n",
    "open_publication.close()\n",
    "#pprint.pprint(publication_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2623ed5e",
   "metadata": {},
   "source": [
    "### Write Publication Schema Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d96fc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('publication', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d81675",
   "metadata": {},
   "source": [
    "### Insert values Publication into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58aca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginInsert('publication')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c120bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fillTable(publication_dict, open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d79db5",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8281844",
   "metadata": {},
   "source": [
    "### Read Dataset TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594f49d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Dataset TSV\n",
    "open_dataset = open(\"dataset.tsv\", \"r\")\n",
    "\n",
    "# Read Header\n",
    "header = open_dataset.readline()\n",
    "# Read Example\n",
    "example = open_dataset.readline()\n",
    "\n",
    "# Key = ID, Value = Publications Name\n",
    "dataset_dict = dict()\n",
    "for row in open_dataset:\n",
    "    split_row =  row.split(\"\\t\")\n",
    "    \n",
    "    if split_row[1] == '':\n",
    "        continue\n",
    "    \n",
    "    if '\\n' in split_row[len(split_row)-1]:\n",
    "        split_row[len(split_row)-1] = split_row[len(split_row)-1].rstrip()\n",
    "        \n",
    "    dataset_id = split_row[0]\n",
    "    \n",
    "    count = 0\n",
    "    field_list = list()\n",
    "    while count < 24:\n",
    "        if split_row[count] != '':\n",
    "            field_value = split_row[count]\n",
    "            if '\"' in field_value:\n",
    "                field_value = field_value.replace('\"', '')\n",
    "            field_list.append(field_value)\n",
    "        else:\n",
    "            field_list.append(\"NULL\")\n",
    "        count += 1\n",
    "    \n",
    "    dataset_dict[dataset_id] = field_list\n",
    "\n",
    "open_dataset.close()\n",
    "pprint.pprint(dataset_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a46bd2",
   "metadata": {},
   "source": [
    "### Write Dataset Schema Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39cabaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('dataset', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924a8fb5",
   "metadata": {},
   "source": [
    "### Insert values Dataset into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824ef10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginInsert('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817d24a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fillTable(dataset_dict, open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246d895f",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4ca279",
   "metadata": {},
   "source": [
    "### Read Gene List TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7f6aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Gene List TSV\n",
    "open_genelist = open(\"gene_list.tsv\", \"r\")\n",
    "\n",
    "header = open_genelist.readline()\n",
    "\n",
    "gene_symbol_list = list()\n",
    "for row in open_genelist:\n",
    "    split_genelist = row.split(\"\\t\")\n",
    "    gene_symbol = split_genelist[0]\n",
    "    gene_id = split_genelist[1]\n",
    "\n",
    "    gene_symbol_list.append(gene_symbol)\n",
    "\n",
    "open_genelist.close()\n",
    "\n",
    "def extractHarCom(begin, end, compare_list, field_num):\n",
    "    # Create Gene Dictionary\n",
    "    gen_dict = dict() # Key: ID, Value: List of field\n",
    "    \n",
    "    # Extract information from Harmonizome.sql\n",
    "    begin = begin\n",
    "    end = end + 1\n",
    "\n",
    "    length = end - begin\n",
    "    id_index = 0\n",
    "    with open('harmonizome.sql', 'r') as f:\n",
    "        count = 0\n",
    "        for line in itertools.islice(f, begin-1, end):\n",
    "            if count == length:\n",
    "                print(line)\n",
    "                break\n",
    "            count += 1\n",
    "            quote = False\n",
    "            slash = False\n",
    "\n",
    "            row = line.rstrip()\n",
    "            if row[0] == '(':\n",
    "                final_str = ''\n",
    "                for i in row:\n",
    "                    if i == \"'\" and quote == False:\n",
    "                        quote = True\n",
    "                    elif slash == True:\n",
    "                        slash = False\n",
    "                    elif \"\\\\\" == i and quote == True:\n",
    "                        slash = True\n",
    "                    elif i == \"'\" and quote == True:\n",
    "                        quote = False\n",
    "                    elif quote == True:\n",
    "                        if \",\" in i:\n",
    "                            final_str += '*'\n",
    "                        else:\n",
    "                            final_str += i\n",
    "                    else:\n",
    "                        final_str += i\n",
    "                final_str = final_str.replace(\"'\", \"\")\n",
    "                final_str = final_str[1:-2]\n",
    "                split_list = final_str.split(',')\n",
    "                gene = split_list[field_num]\n",
    "\n",
    "                if gene in compare_list:\n",
    "                    row_list = list()\n",
    "\n",
    "                    for value in split_list:\n",
    "                        if '*' in value:\n",
    "                            row_list.append(value.replace(\"*\", \",\"))\n",
    "                        else:\n",
    "                            row_list.append(value)\n",
    "\n",
    "                    gen_dict[gene] = row_list\n",
    "\n",
    "                id_index = split_list[0]\n",
    "    return(gen_dict, id_index)\n",
    "\n",
    "gene_dict, id_index = extractHarCom(71906861, 71963595, gene_symbol_list, 1)\n",
    "pprint.pprint(gene_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f31db14",
   "metadata": {},
   "source": [
    "### Write Gene List Schema Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a82e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('gene', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfee1998",
   "metadata": {},
   "source": [
    "### Insert values Gene List into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6fb3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginInsert('gene')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945cb5b2",
   "metadata": {},
   "source": [
    "### Create output directory\n",
    "Create an output directory if it does not exit already and change current directory to output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c02d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TableOutput(table_name, gen_dict, schema_list):\n",
    "    start_dir = os.getcwd()\n",
    "    output_path = '{}/achilles_tables'.format(start_dir)\n",
    "    field = ''\n",
    "    if os.path.isdir(output_path):\n",
    "        # Change the current working directory to output directory\n",
    "        os.chdir(output_path)\n",
    "        write_table = open('{}.tsv'.format(table_name), \"w\")\n",
    "        for count, row in enumerate(schema_list): \n",
    "            x = re.search(\"  `(.*?)`\", row)\n",
    "            \n",
    "            if not x and field != '':\n",
    "                write_table.write(\"{}\".format(field)) \n",
    "                field = ''\n",
    "            elif x and field != '':\n",
    "                write_table.write(\"{}\\t\".format(field)) \n",
    "            \n",
    "            if x:\n",
    "                start_end_tup = x.span()\n",
    "                start_index = int(start_end_tup[0]) + 3\n",
    "                end_index = int(start_end_tup[1]) - 1\n",
    "                field = row[start_index:end_index]    \n",
    "\n",
    "        write_table.write(\"\\n\")\n",
    "\n",
    "        for key, value_list in gen_dict.items():\n",
    "            for count, value in enumerate(value_list):\n",
    "                if count == len(value_list)-1:\n",
    "                    write_table.write(\"{}\".format(value)) \n",
    "                else:\n",
    "                    write_table.write(\"{}\\t\".format(value)) \n",
    "            write_table.write(\"\\n\")\n",
    "    else:\n",
    "        field = ''\n",
    "        # Create output directory if it does not exist\n",
    "        os.mkdir(output_path)\n",
    "        os.chdir(output_path)\n",
    "        write_table = open('{}.tsv'.format(table_name), \"w\")\n",
    "        for count, row in enumerate(schema_list):   \n",
    "            x = re.search(\"  `(.*?)`\", row)\n",
    "            \n",
    "            x = re.search(\"  `(.*?)`\", row)\n",
    "            \n",
    "            if not x and field != '':\n",
    "                write_table.write(\"{}\".format(field)) \n",
    "                field = ''\n",
    "            elif x and field != '':\n",
    "                write_table.write(\"{}\\t\".format(field)) \n",
    "            \n",
    "            if x:\n",
    "                start_end_tup = x.span()\n",
    "                start_index = int(start_end_tup[0]) + 3\n",
    "                end_index = int(start_end_tup[1]) - 1\n",
    "                field = row[start_index:end_index]   \n",
    "                \n",
    "        write_table.write(\"\\n\")\n",
    "\n",
    "        for key, value_list in gen_dict.items():\n",
    "            for count, value in enumerate(value_list):\n",
    "                if count == len(value_list)-1:\n",
    "                    write_table.write(\"{}\".format(value)) \n",
    "                else:\n",
    "                    write_table.write(\"{}\\t\".format(value)) \n",
    "            write_table.write(\"\\n\")\n",
    "    \n",
    "    write_table.close()    \n",
    "    os.chdir(start_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c98cad5",
   "metadata": {},
   "source": [
    "### Get entrez id and description from gene symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea02c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(url):\n",
    "    myResponse = requests.get(url)\n",
    "    entrez_id = \"\"\n",
    "    uniprot_ids = \"\"\n",
    "    gene_group = \"\"\n",
    "    gene_group_id = \"\"\n",
    "    \n",
    "    if (myResponse.ok):\n",
    "        file = bs.BeautifulSoup(myResponse.text, \"lxml\")\n",
    "        tag = file.find('response')\n",
    "        str_name = tag.findAll(['str', 'arr'])\n",
    "        active = False\n",
    "        \n",
    "        for row in str_name:\n",
    "            if \"entrez_id\" == row.get(\"name\"):\n",
    "                entrez_id = row.text\n",
    "                \n",
    "            # Check if protein produce from gene\n",
    "            if \"locus_type\" == row.get(\"name\"):                \n",
    "                if row.text == \"gene with protein product\":\n",
    "                    active = True\n",
    "                    continue    \n",
    "            if  active == True and \"uniprot_ids\" == row.get(\"name\"):\n",
    "                uniprot_ids = row.text\n",
    "                active = False\n",
    "            \n",
    "            if \"gene_group\" == row.get(\"name\"):\n",
    "                gene_group = row.text\n",
    "                \n",
    "            if \"gene_group_id\" == row.get(\"name\"):\n",
    "                gene_group_id = row.text\n",
    "        \n",
    "        gene_group = str(gene_group).strip()\n",
    "        gene_group_id = str(gene_group_id).strip()\n",
    "        \n",
    "        if \"\\n\" in gene_group:\n",
    "            gene_group_split = gene_group.split(\"\\n\")\n",
    "            gene_group = gene_group_split[0]\n",
    "            \n",
    "        if \"\\n\" in gene_group_id:\n",
    "            gene_group_id_split = gene_group_id.split(\"\\n\")\n",
    "            gene_group_id = gene_group_id_split[0]\n",
    "            \n",
    "                \n",
    "    return(entrez_id, uniprot_ids, gene_group, gene_group_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8625b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncbi_id(entrez_id):\n",
    "    name = \"NULL\"\n",
    "    desc = \"NULL\"\n",
    "\n",
    "    ncbi_url = \"https://www.ncbi.nlm.nih.gov/gene/{}\".format(entrez_id)\n",
    "    page = requests.get(ncbi_url)\n",
    "    soup = bs.BeautifulSoup(page.text, \"html.parser\")\n",
    "    results = soup.find(id=\"summaryDl\")\n",
    "    res = results.find_all(['dd', 'dt'])\n",
    "\n",
    "    active_summary = False\n",
    "    active_name = False\n",
    "    for row in res:\n",
    "        if \"Summary\" in row.text:\n",
    "            active_summary = True\n",
    "        elif active_summary == True:\n",
    "            desc = row.text\n",
    "            active_summary = False\n",
    "\n",
    "        if \"Full Name\" in row.text:\n",
    "            active_name = True\n",
    "        elif active_name == True:\n",
    "            name = row.text.replace(\"provided by HGNC\", \"\")\n",
    "            active_name = False\n",
    "    #print(name, desc, ncbi_url)\n",
    "    return(name, desc, ncbi_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf202d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_wprot_dict = dict()\n",
    "gene_group_list = list() \n",
    "\n",
    "gene_symbol_group_list = list()\n",
    "gene_group_id_list = list()\n",
    "gene_group_map_dict = dict()\n",
    "\n",
    "try:\n",
    "    gene_wprot_dict = pickle.load(open(\"gene_wprot_dict.pkl\", \"rb\"))\n",
    "    gene_group_map_dict = pickle.load(open(\"gene_group_map_dict.pkl\", \"rb\"))\n",
    "\n",
    "except:\n",
    "    gene_list = list()\n",
    "    for gene in gene_dict.keys():\n",
    "        gene_list.append(gene)\n",
    "    \n",
    "    #pprint.pprint(gene_list)\n",
    "    \n",
    "    # entrez_id \n",
    "    entrez_id_list = list()\n",
    "    gene_wprot_dict = dict()\n",
    "\n",
    "    # Genes not in current Harmonizome DB\n",
    "    leftover_gene_set = set(gene_symbol_list) - set(gene_list)\n",
    "    \n",
    "    for gene in leftover_gene_set:\n",
    "        id_index = int(id_index) + 1\n",
    "\n",
    "        try:\n",
    "            url = \"https://rest.genenames.org/fetch/symbol/{}\".format(gene)\n",
    "            entrez_id, uniprot_ids, gene_group, gene_group_id = get_url(url)\n",
    "            gene_group_list.append(str(gene_group).strip()) \n",
    "            gene_group_id_list.append(str(gene_group_id).strip())\n",
    "            gene_symbol_group_list.append(gene)\n",
    "            \n",
    "            \n",
    "            gene = gene.strip()\n",
    "            uniprot_ids = uniprot_ids.strip()\n",
    "\n",
    "            if uniprot_ids != \"\":\n",
    "                gene_wprot_dict[id_index] = uniprot_ids\n",
    "            \n",
    "            print(gene, \"---\")\n",
    "            name, desc, ncbi_url = ncbi_id(entrez_id)\n",
    "            print(gene, \"***\")\n",
    "            gene_dict[gene] = [id_index, gene, entrez_id, name, desc, ncbi_url, \"NULL\", \"NULL\"]\n",
    "        except:\n",
    "            print(\"---\",gene)\n",
    "            gene_dict[gene] = [id_index, gene, \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\"]\n",
    "\n",
    "    for index in range(0, len(gene_group_id_list)):\n",
    "        gene_group_map_dict[gene_symbol_group_list[index]] = [gene_group_id_list[index], gene_group_list[index]]       \n",
    "    \n",
    "    pprint.pprint(gene_group_map_dict)\n",
    "    \n",
    "    pickle.dump(gene_dict, open(\"gene_dict.pkl\", \"wb\"))\n",
    "    pickle.dump(gene_wprot_dict, open(\"gene_wprot_dict.pkl\", \"wb\"))\n",
    "    pickle.dump(gene_group_map_dict, open(\"gene_group_map_dict.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651c411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TableOutput('gene', gene_dict, schema_dict['gene'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "14ca5e8f",
   "metadata": {},
   "source": [
    "pprint.pprint(gene_wprot_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b06a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "genesymbol_to_geneid_dict = dict()\n",
    "\n",
    "for key, value in gene_dict.items():\n",
    "    genesymbol_to_geneid_dict[value[1]] = value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eee8a2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fillTable(gene_dict, open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814aeefe",
   "metadata": {},
   "source": [
    "### Write leftover genes in dataset not in current Harmonizome"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f1bbfe9f",
   "metadata": {},
   "source": [
    "gene_list = list()\n",
    "for gene in gene_dict.keys():\n",
    "    gene_list.append(gene)\n",
    "\n",
    "# Genes not in current Harmonizome DB\n",
    "leftover_gene_set = set(gene_symbol_list) - set(gene_list)\n",
    "\n",
    "print(\"Number of genes in dataset: {}\".format(len(gene_symbol_list)))\n",
    "print(\"Number of genes not in Harmonizome db: {}\".format(len(gene_list)))\n",
    "\n",
    "open_write_gene_achilles = open(\"achilles_gene.tsv\", \"w\")\n",
    "open_write_gene_achilles.write(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(\"Gene Identifier\", \"Symbol\", \"NCBI_Entrez_Gene_ID\", \"Name\", \"Description\", \"NCBI_Entrez_Gene_URL\", \"IDG_Family_fk\", \"IDG_TDL_Class_fk\"))\n",
    "\n",
    "for gene in leftover_gene_set:\n",
    "    id_index = int(id_index) + 1\n",
    "    open_write_gene_achilles.write(\"\\n{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(id_index, gene, \"\", \"\", \"\", \"\", \"\", \"\"))\n",
    "open_write_gene_achilles.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e95a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractHarAll(begin, end):\n",
    "    # Create Gene Dictionary\n",
    "    gen_dict = dict() # Key: ID, Value: List of field\n",
    "    \n",
    "    # Extract information from Harmonizome.sql\n",
    "    begin = begin\n",
    "    end = end + 1\n",
    "\n",
    "    length = end - begin\n",
    "    id_index = 0\n",
    "    with open('harmonizome.sql', 'r') as f:\n",
    "        count = 0\n",
    "        for line in itertools.islice(f, begin-1, end):\n",
    "            line = str(line)\n",
    "            if count == length:\n",
    "                print(line)\n",
    "                break\n",
    "            count += 1\n",
    "            quote = False\n",
    "            slash = False\n",
    "\n",
    "            row = line.rstrip()\n",
    "            if row[0] == '(':\n",
    "                final_str = ''\n",
    "                for i in row:\n",
    "                    if i == \"'\" and quote == False:\n",
    "                        quote = True\n",
    "                    elif slash == True:\n",
    "                        slash = False\n",
    "                    elif \"\\\\\" == i and quote == True:\n",
    "                        slash = True\n",
    "                    elif i == \"'\" and quote == True:\n",
    "                        quote = False\n",
    "                    elif quote == True:\n",
    "                        if \",\" in i:\n",
    "                            final_str += '*'\n",
    "                        else:\n",
    "                            final_str += i\n",
    "                    else:\n",
    "                        final_str += i\n",
    "                final_str = final_str.replace(\"'\", \"\")\n",
    "                final_str = final_str[1:-2]\n",
    "                split_list = final_str.split(',')\n",
    "                gene_syn = split_list[0]\n",
    "\n",
    "                row_list = list()\n",
    "\n",
    "                for value in split_list:\n",
    "                    if '*' in value:\n",
    "                        row_list.append(value.replace(\"*\", \",\"))\n",
    "                    else:\n",
    "                        if value == \"\":\n",
    "                            row_list.append(\"NULL\")\n",
    "                        else:\n",
    "                            row_list.append(value)\n",
    "\n",
    "                gen_dict[gene_syn] = row_list\n",
    "\n",
    "                id_index = split_list[0]\n",
    "    return(gen_dict, id_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1819f48",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write Gene Syn Schema Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aea923",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('gene_synonym', open_sql)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "31ea8129",
   "metadata": {},
   "source": [
    "temp_gene_syn_dict, id_index = extractHarAll(72296053, 72361564)\n",
    "\n",
    "pprint.pprint(temp_gene_syn_dict)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d302d6d0",
   "metadata": {},
   "source": [
    "gene_id_list = list()\n",
    "for key, value in gene_dict.items():\n",
    "    gene_id_list.append(value[0])\n",
    "print(gene_id_list)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ade53349",
   "metadata": {},
   "source": [
    "gene_syn_dict = dict()\n",
    "for key, value in temp_gene_syn_dict.items():\n",
    "    gene_fk = str(value[2]).strip()\n",
    "\n",
    "    if gene_fk in gene_id_list:\n",
    "        gene_syn_id = str(value[0]).strip()\n",
    "        gene_syn_dict[str(value[1])] = [gene_syn_id, str(value[1]), gene_fk]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0dcc7231",
   "metadata": {},
   "source": [
    "# Assign new key to gene_syn_dict\n",
    "gene_syn_dict = dict()\n",
    "for key, value in temp_gene_syn_dict.items():\n",
    "    gene_syn_dict[value[1]] = value\n",
    "\n",
    "# Get all gene id\n",
    "gene_symbol_list = list()\n",
    "for key, value in gene_dict.items():\n",
    "    gene_symbol_list.append(value[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b59542",
   "metadata": {},
   "source": [
    "### Parse Homo Sapiens Gene Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27063ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sapiens = open(\"Homo_sapiens.gene_info.tsv\", \"r\")\n",
    "open_sapiens.readline()\n",
    "\n",
    "gene_syn_dict = dict()\n",
    "\n",
    "homo_gene_syn_dict = dict()\n",
    "for row in open_sapiens:\n",
    "    split_list = row.split(\"\\t\")\n",
    "    gene_syn_list = split_list[4].split(\"|\")\n",
    "    \n",
    "    final_gene_syn_list = list()\n",
    "    for gene in gene_syn_list:\n",
    "        if \"-\" == gene:\n",
    "            final_gene_syn_list.append(\"NULL\")\n",
    "        else:\n",
    "            final_gene_syn_list.append(gene)\n",
    "        \n",
    "    gene_symbol = split_list[2]\n",
    "    homo_gene_syn_dict[gene_symbol] = final_gene_syn_list\n",
    "\n",
    "dup_gene_list = list()\n",
    "count = 0\n",
    "for key, value in homo_gene_syn_dict.items():\n",
    "    gene_symbol = key\n",
    "    if gene_symbol in genesymbol_to_geneid_dict.keys(): \n",
    "        for gene in value:\n",
    "            if gene == 'NULL':\n",
    "                continue\n",
    "            if gene.upper() not in dup_gene_list:      \n",
    "                count += 1\n",
    "                gene_syn_dict[count] = [count, gene, genesymbol_to_geneid_dict[gene_symbol]]\n",
    "                dup_gene_list.append(gene.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0705db64",
   "metadata": {},
   "source": [
    "### Insert values Gene Syn into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b052cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginInsert('gene_synonym')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f834766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fillTable(gene_syn_dict, open_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056b6add",
   "metadata": {},
   "outputs": [],
   "source": [
    "TableOutput('gene_synonym', gene_syn_dict, schema_dict['gene_synonym'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f1ccca",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write Protein Schema Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acab0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('protein', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683bc792",
   "metadata": {},
   "source": [
    "### Insert values Protein into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59c44ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect Gene Id from gene_dict\n",
    "gene_id_list = list()\n",
    "for key, value in gene_dict.items():\n",
    "    gene_id_list.append(value[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f7ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_protein_dict, index_idx = extractHarCom(72901445, 72921124, gene_id_list, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e665cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_dict = dict()\n",
    "for key, value in temp_protein_dict.items():\n",
    "    protein_dict[value[1]] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cc6cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(protein_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d467c47",
   "metadata": {},
   "source": [
    "### Add Protein not in current db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959cdbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_idx = int(index_idx)\n",
    "try:\n",
    "    protein_dict = pickle.load(open(\"protein_dict.pkl\", \"rb\"))\n",
    "\n",
    "except:\n",
    "    for key, value in gene_wprot_dict.items():\n",
    "        gene = key\n",
    "        uniprot_id = value\n",
    "\n",
    "        protein_name = \"\"\n",
    "        prot_desc = \"\"\n",
    "        alternative_name = \"\"\n",
    "        url = \"https://www.uniprot.org/uniprot/{}\".format(value)\n",
    "        myResponse = requests.get(url)\n",
    "\n",
    "        if (myResponse.ok):\n",
    "            soup = bs.BeautifulSoup(myResponse.text, \"html.parser\")\n",
    "            meta_res = soup.find_all(\"meta\")\n",
    "            for row in meta_res:\n",
    "                if row.get(\"name\") == \"description\":\n",
    "                    prot_desc = row.get('content')\n",
    "                    break\n",
    "\n",
    "            span_res = soup.find_all(\"span\")\n",
    "            for row in span_res:\n",
    "                if row.get(\"property\") == \"alternateName\":\n",
    "                    alternative_name = row.text    \n",
    "                    alternative_name = alternative_name.replace(\"(\", \"\").replace(\")\", \"\")\n",
    "                    break\n",
    "\n",
    "            h1_res = soup.find_all(\"h1\")\n",
    "            for row in h1_res:\n",
    "                if row.get(\"property\") == \"name\":\n",
    "                    protein_name = row.text\n",
    "                    break\n",
    "        \n",
    "        if alternative_name == '':\n",
    "            continue\n",
    "        index_idx += 1\n",
    "        protein_dict[alternative_name] = [int(index_idx) + 1, alternative_name, uniprot_id, protein_name, prot_desc, url, key]\n",
    "    pickle.dump(protein_dict, open(\"protein_dict.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872bb623",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(protein_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c36875",
   "metadata": {},
   "outputs": [],
   "source": [
    "TableOutput('protein', protein_dict, schema_dict['protein'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68df8fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginInsert('protein')\n",
    "fillTable(protein_dict, open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b68aea",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write Dataset To Publication Schema Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd183c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('datasets_to_publications', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0549fc7f",
   "metadata": {},
   "source": [
    "### Insert values Dataset To Publication into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2204db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id_list = list()\n",
    "for dataset_id in dataset_dict.keys():\n",
    "    dataset_id_list.append(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b794fe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_to_publications_dict, index_idx = extractHarCom(71901433, 71901603, dataset_id_list, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb51c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginInsert('datasets_to_publications')\n",
    "fillTable(datasets_to_publications_dict, open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed81f0e",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write Geneset Schema Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404e729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('gene_set', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7117473",
   "metadata": {},
   "source": [
    "### Insert values Geneset into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cc7cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Geneset List TSV (processed data)\n",
    "open_geneset = open(\"attribute_list.tsv\", \"r\")\n",
    "\n",
    "header = open_geneset.readline()\n",
    "\n",
    "geneset_list = list()\n",
    "for row in open_geneset:\n",
    "    split_genelist = row.split(\"\\t\")\n",
    "    attribute = split_genelist[0]\n",
    "    attribute_id = split_genelist[1]\n",
    "\n",
    "    geneset_list.append(attribute)\n",
    "\n",
    "open_geneset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2a899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractHarComDup(begin, end, compare_list, field_one, field_two, dataset_fk):\n",
    "    # Create Gene Dictionary\n",
    "    gen_dict = dict() # Key: ID, Value: List of field\n",
    "    \n",
    "    # Extract information from Harmonizome.sql\n",
    "    begin = begin\n",
    "    end = end + 1\n",
    "\n",
    "    length = end - begin\n",
    "    id_index = 0\n",
    "    with open('harmonizome.sql', 'r') as f:\n",
    "        count = 0\n",
    "        for line in itertools.islice(f, begin-1, end):\n",
    "            line = str(line)\n",
    "            if count == length:\n",
    "                print(line)\n",
    "                break\n",
    "            count += 1\n",
    "            quote = False\n",
    "            slash = False\n",
    "\n",
    "            row = line.rstrip()\n",
    "            if row[0] == '(':\n",
    "                final_str = ''\n",
    "                for i in row:\n",
    "                    if i == \"'\" and quote == False:\n",
    "                        quote = True\n",
    "                    elif slash == True:\n",
    "                        slash = False\n",
    "                    elif \"\\\\\" == i and quote == True:\n",
    "                        slash = True\n",
    "                    elif i == \"'\" and quote == True:\n",
    "                        quote = False\n",
    "                    elif quote == True:\n",
    "                        if \",\" in i:\n",
    "                            final_str += '*'\n",
    "                        else:\n",
    "                            final_str += i\n",
    "                    else:\n",
    "                        final_str += i\n",
    "                final_str = final_str.replace(\"'\", \"\")\n",
    "                final_str = final_str[1:-2]\n",
    "                split_list = final_str.split(',')\n",
    "                \n",
    "                geneset_name = split_list[field_one]\n",
    "                dataset_id = split_list[field_two]\n",
    "                \n",
    "                identifier = split_list[0]\n",
    "                \n",
    "                if geneset_name in compare_list and dataset_id == dataset_fk:\n",
    "                    row_list = list()\n",
    "\n",
    "                    for value in split_list:\n",
    "                        if '*' in value:\n",
    "                            row_list.append(value.replace(\"*\", \",\"))\n",
    "                        else:\n",
    "                            row_list.append(value)\n",
    "\n",
    "                    gen_dict[identifier] = row_list\n",
    "\n",
    "                id_index = split_list[0]\n",
    "    return(gen_dict, id_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da0cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# begin, end, compare_list, field_one, field_two, dataset_fk\n",
    "geneset_dict, index_idx = extractHarComDup(71963633, 72296024, geneset_list, 1, 5, \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e69957",
   "metadata": {},
   "outputs": [],
   "source": [
    "geneset_to_genesetid_dict = dict()\n",
    "\n",
    "for key, value in geneset_dict.items():\n",
    "    geneset_to_genesetid_dict[value[1]] = value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daccc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "geneset_id_list = list()\n",
    "for geneset_id, value in geneset_dict.items():\n",
    "    geneset_id_list.append(geneset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f187bf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginInsert('gene_set')\n",
    "fillTable(geneset_dict, open_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e21c4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TableOutput('gene_set', geneset_dict, schema_dict['gene_set'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accf4560",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write Attribute Schema Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2e0b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('attribute', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ee241b",
   "metadata": {},
   "source": [
    "### Insert values Attribute into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316c7a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_list = list()\n",
    "for key, value in geneset_dict.items():\n",
    "    attribute_list.append(value[7])\n",
    "\n",
    "attribute_dict, index_idx = extractHarCom(71601358, 71896880, attribute_list, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fb9572",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginInsert('attribute')\n",
    "fillTable(attribute_dict, open_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8871bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TableOutput('attribute', attribute_dict, schema_dict['attribute'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d02263f",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write Associations Schema Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e53e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('association', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d2ce42",
   "metadata": {},
   "source": [
    "### Insert values Associations into master SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0ebaf2",
   "metadata": {},
   "source": [
    "try:\n",
    "    association_dict = pickle.load(open(\"association_dict.pkl\", \"rb\"))\n",
    "\n",
    "except:\n",
    "    \n",
    "    geneset_id_list = list()\n",
    "    gene_id_list = list()\n",
    "    \n",
    "    for key, value in gene_dict.items():\n",
    "        gene_id_list.append(value[0])\n",
    "        \n",
    "    for key, value in geneset_dict.items():\n",
    "        geneset_id_list.append(value[0])\n",
    "    \n",
    "    pprint.pprint(gene_id_list)\n",
    "    pprint.pprint(geneset_id_list)\n",
    "    \n",
    "    #association_dict, index_idx = extractHarCom(50, 71601328, gene_id_list, 1)\n",
    "    \n",
    "    association_dict = dict() # Key: ID, Value: List of field\n",
    "    \n",
    "    # Extract information from Harmonizome.sql\n",
    "    begin = 50\n",
    "    end = 71601328\n",
    "\n",
    "    length = end - begin\n",
    "    id_index = 0\n",
    "    \n",
    "    left_over_geneset_id_list = list()\n",
    "    left_over_gene_id_list = list()\n",
    "    with open('harmonizome.sql', 'r') as f:\n",
    "        count = 0\n",
    "        for line in itertools.islice(f, begin-1, end):\n",
    "            if count == length:\n",
    "                print(line)\n",
    "                break\n",
    "            count += 1\n",
    "            quote = False\n",
    "            slash = False\n",
    "\n",
    "            row = line.rstrip()\n",
    "            if row[0] == '(':\n",
    "                final_str = ''\n",
    "                for i in row:\n",
    "                    if i == \"'\" and quote == False:\n",
    "                        quote = True\n",
    "                    elif slash == True:\n",
    "                        slash = False\n",
    "                    elif \"\\\\\" == i and quote == True:\n",
    "                        slash = True\n",
    "                    elif i == \"'\" and quote == True:\n",
    "                        quote = False\n",
    "                    elif quote == True:\n",
    "                        if \",\" in i:\n",
    "                            final_str += '*'\n",
    "                        else:\n",
    "                            final_str += i\n",
    "                    else:\n",
    "                        final_str += i\n",
    "                final_str = final_str.replace(\"'\", \"\")\n",
    "                final_str = final_str[1:-2]\n",
    "                split_list = final_str.split(',')\n",
    "                \n",
    "                index = split_list[0]\n",
    "                gene = split_list[1]\n",
    "                gene_set = split_list[2]\n",
    "                \n",
    "                if gene in gene_id_list and gene_set in geneset_id_list:\n",
    "                    row_list = list()\n",
    "\n",
    "                    for value in split_list:\n",
    "                        if '*' in value:\n",
    "                            value = value.replace(\"*\", \",\")\n",
    "                        \n",
    "                        if value.isnumeric():\n",
    "                            row_list.append(int(value))\n",
    "                        else:\n",
    "                            row_list.append(value)\n",
    "\n",
    "                    association_dict[index] = row_list\n",
    "                else:\n",
    "                    left_over_geneset_id_list.append(gene_set)\n",
    "                    left_over_gene_id_list.append(gene)\n",
    "                    \n",
    "                id_index = split_list[0]\n",
    "            \n",
    "    print(id_index)\n",
    "\n",
    "    #association_dict, index_idx = extractHarAll(50, 71601328)\n",
    "    pickle.dump(association_dict, open(\"association_dict.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086e2e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#association_index = 1290000029563\n",
    "f = h5.File(\"gene_attribute_matrix_standardized.h5\", \"r\")\n",
    "\n",
    "datasetNames = [n for n in f.keys()]\n",
    "data = f['data']['matrix']\n",
    "\n",
    "meta_colid = f['meta']['colid']\n",
    "meta_index = f['meta']['index']\n",
    "\n",
    "geneset_list = list()\n",
    "for geneset in meta_colid:\n",
    "    geneset_list.append(geneset.decode('UTF-8'))\n",
    "\n",
    "gene_list = list()\n",
    "for gene in meta_index:\n",
    "    gene_list.append(gene.decode('UTF-8'))\n",
    "\n",
    "association_dict = dict()\n",
    "association_index = 1000000000\n",
    "\n",
    "# geneset_to_genesetid_dict\n",
    "# genesymbol_to_geneid_dict \n",
    "\n",
    "def threshholdValue(value):\n",
    "    if value < 0:\n",
    "        return -1\n",
    "    else: \n",
    "        return 1\n",
    "\n",
    "temp_association_dict = dict()\n",
    "\n",
    "for index_gene, geneset_row in enumerate(data):\n",
    "    gene = gene_list[index_gene] \n",
    "    \n",
    "    if gene in genesymbol_to_geneid_dict.keys():\n",
    "        gene_id = genesymbol_to_geneid_dict[gene]\n",
    "    else:\n",
    "        continue\n",
    "        #gene_id = \"NULL\"\n",
    "    \n",
    "    for index_geneset, gene_value in enumerate(geneset_row):\n",
    "        geneset = geneset_list[index_geneset]\n",
    "        geneset_id = geneset_to_genesetid_dict[geneset]\n",
    "        \n",
    "        if geneset_id == \"NULL\":\n",
    "            continue\n",
    "        \n",
    "        thvalue = threshholdValue(gene_value)\n",
    "        \n",
    "        if thvalue == 1:\n",
    "            if gene_value < 1:\n",
    "                continue\n",
    "        elif thvalue == -1:\n",
    "            if gene_value > -1:\n",
    "                continue\n",
    "        \n",
    "        association_index += 1\n",
    "        temp_association_dict[association_index] = [association_index, gene, geneset_id, \"NULL\", \"NULL\", round(float(gene_value), 5), thvalue]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953ccc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_two_association_dict = dict()\n",
    "association_index = 1000000000\n",
    "\n",
    "for key, value in temp_association_dict.items():\n",
    "    gene = value[1]\n",
    "    geneset_id = value[2]\n",
    "    gene_value = value[5]\n",
    "    \n",
    "    if geneset_id not in temp_two_association_dict.keys():\n",
    "        temp_two_association_dict[geneset_id] = list()\n",
    "    else:\n",
    "        temp_two_association_dict[geneset_id].append([gene, gene_value])\n",
    "\n",
    "print(len(temp_two_association_dict))\n",
    "association_dict = dict()\n",
    "for key, value in temp_two_association_dict.items():\n",
    "    geneset_id = key\n",
    "    genes_in_geneset_list = temp_two_association_dict[key]\n",
    "    genes_in_geneset_list.sort(key = lambda x: x[1])\n",
    "    \n",
    "    for pair1, pair2 in genes_in_geneset_list[-30:]:\n",
    "        genesymbol = pair1\n",
    "        gene_value = pair2\n",
    "        \n",
    "        thvalue = threshholdValue(gene_value)\n",
    "        \n",
    "        association_index += 1\n",
    "        association_dict[association_index] = [association_index, genesymbol_to_geneid_dict[genesymbol], geneset_id, \"NULL\", \"NULL\", gene_value, thvalue]\n",
    "    \n",
    "    for pair3, pair4 in genes_in_geneset_list[:30]:\n",
    "        genesymbol = pair3\n",
    "        gene_value = pair4\n",
    "        \n",
    "        thvalue = threshholdValue(gene_value)\n",
    "        \n",
    "        association_index += 1\n",
    "        association_dict[association_index] = [association_index, genesymbol_to_geneid_dict[genesymbol], geneset_id, \"NULL\", \"NULL\", gene_value, thvalue]\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3357ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(association_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d31c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillTableAssoc(resource_dict, open_sql):\n",
    "    index = 0\n",
    "    for key, value in resource_dict.items():\n",
    "        if index == len(resource_dict.keys())-1:\n",
    "            open_sql.write('\\n(')\n",
    "            for count, entry in enumerate(value):\n",
    "                entry = str(entry)\n",
    "                if count == len(value)-1:\n",
    "                    entry = entry.rstrip()\n",
    "                    if entry == \" \" or entry == \"\":\n",
    "                        open_sql.write(\"{});\".format(\"NULL\"))\n",
    "                    elif entry.isnumeric() or isinstance(entry, float):\n",
    "                        open_sql.write(\"{});\".format(entry))\n",
    "                    elif \"NULL\" == entry or \"Null\" == entry:\n",
    "                        open_sql.write(\"{});\".format(entry))\n",
    "                    else:\n",
    "                        open_sql.write('{});'.format(entry))\n",
    "                else:\n",
    "                    if entry == \" \" or entry == \"\":\n",
    "                        open_sql.write(\"{},\".format(\"NULL\"))\n",
    "                    elif entry.isnumeric() or isinstance(entry, float):\n",
    "                        open_sql.write(\"{},\".format(entry))\n",
    "                    elif \"NULL\" == entry:\n",
    "                        open_sql.write(\"{},\".format(entry))\n",
    "                    else:\n",
    "                        open_sql.write('{},'.format(entry))\n",
    "            break\n",
    "            \n",
    "        open_sql.write('\\n(')   \n",
    "        for count, entry in enumerate(value):\n",
    "            entry = str(entry)\n",
    "            if count == len(value)-1:\n",
    "                entry = entry.rstrip()\n",
    "                if entry == \" \" or entry == \"\":\n",
    "                    open_sql.write(\"{}),\".format(\"NULL\"))\n",
    "                elif entry.isnumeric() or isinstance(entry, float):\n",
    "                    open_sql.write(\"{}),\".format(entry))\n",
    "                elif \"NULL\" == entry or \"Null\" == entry:\n",
    "                    open_sql.write(\"{}),\".format(entry))\n",
    "                else:\n",
    "                    open_sql.write('{}),'.format(entry))\n",
    "            else:\n",
    "                if entry == \" \" or entry == \"\":\n",
    "                    open_sql.write(\"{},\".format(\"NULL\"))\n",
    "                elif entry.isnumeric() or isinstance(entry, float):\n",
    "                    open_sql.write(\"{},\".format(entry))\n",
    "                elif \"NULL\" == entry:\n",
    "                    open_sql.write(\"{},\".format(entry))\n",
    "                else:\n",
    "                    open_sql.write('{},'.format(entry))\n",
    "        index += 1\n",
    "        \n",
    "    open_sql.write(\"\\nUNLOCK TABLES;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9707d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginInsert('association')\n",
    "fillTableAssoc(association_dict, open_sql)\n",
    "TableOutput('association', association_dict, schema_dict['association'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7520a6",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write Attribute Type Schema Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bd1a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('attribute_type', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15273f87",
   "metadata": {},
   "source": [
    "### Insert values Attribute Type into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10ad6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_attribute_type = open(\"attribute_type.tsv\", \"r\")\n",
    "\n",
    "# Read Header\n",
    "header = open_attribute_type.readline()\n",
    "# Read Example\n",
    "example = open_attribute_type.readline()\n",
    "\n",
    "# Key = ID, Value = Publications Name\n",
    "attribute_type_dict = dict()\n",
    "for row in open_attribute_type:\n",
    "    split_row =  row.split(\"\\t\")\n",
    "    \n",
    "    if split_row[1] == '':\n",
    "        continue\n",
    "    \n",
    "    if '\\n' in split_row[len(split_row)-1]:\n",
    "        split_row[len(split_row)-1] = split_row[len(split_row)-1].rstrip()\n",
    "        \n",
    "    attribute_type_id = split_row[0]\n",
    "    \n",
    "    count = 0\n",
    "    field_list = list()\n",
    "    while count < 3:\n",
    "        if split_row[count] != '':\n",
    "            field_value = split_row[count]\n",
    "            if '\"' in field_value:\n",
    "                field_value = field_value.replace('\"', '')\n",
    "            field_list.append(field_value)\n",
    "        else:\n",
    "            field_list.append(\"NULL\")\n",
    "        count += 1\n",
    "    \n",
    "    attribute_type_dict[attribute_type_id] = field_list\n",
    "\n",
    "open_attribute_type.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1943effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginInsert('attribute_type')\n",
    "fillTable(attribute_type_dict, open_sql)\n",
    "TableOutput('attribute_type', attribute_type_dict, schema_dict['attribute_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb101f65",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write Attribute Group Schema Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c15f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('attribute_group', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261cfc7a",
   "metadata": {},
   "source": [
    "### Insert values Attribute Group into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9961694",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_attribute_group = open(\"attribute_group.tsv\", \"r\")\n",
    "\n",
    "# Read Header\n",
    "header = open_attribute_group.readline()\n",
    "# Read Example\n",
    "example = open_attribute_group.readline()\n",
    "\n",
    "# Key = ID, Value = Publications Name\n",
    "attribute_group_dict = dict()\n",
    "for row in open_attribute_group:\n",
    "    split_row =  row.split(\"\\t\")\n",
    "    \n",
    "    if split_row[1] == '':\n",
    "        continue\n",
    "    \n",
    "    if '\\n' in split_row[len(split_row)-1]:\n",
    "        split_row[len(split_row)-1] = split_row[len(split_row)-1].rstrip()\n",
    "        \n",
    "    attribute_group_id = split_row[0]\n",
    "    \n",
    "    count = 0\n",
    "    field_list = list()\n",
    "    while count < 3:\n",
    "        if split_row[count] != '':\n",
    "            field_value = split_row[count]\n",
    "            if '\"' in field_value:\n",
    "                field_value = field_value.replace('\"', '')\n",
    "            field_list.append(field_value)\n",
    "        else:\n",
    "            field_list.append(\"NULL\")\n",
    "        count += 1\n",
    "    \n",
    "    attribute_group_dict[attribute_group_id] = field_list\n",
    "\n",
    "open_attribute_group.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8dff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginInsert('attribute_group')\n",
    "fillTable(attribute_group_dict, open_sql)\n",
    "TableOutput('attribute_group', attribute_group_dict, schema_dict['attribute_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882f903f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6494185a",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write Dataset Group Schema Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88e4143",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('dataset_group', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8563b5c",
   "metadata": {},
   "source": [
    "### Insert values Dataset Group into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af09ed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_dataset_group = open(\"dataset_group.tsv\", \"r\")\n",
    "\n",
    "# Read Header\n",
    "header = open_dataset_group.readline()\n",
    "# Read Example\n",
    "example = open_dataset_group.readline()\n",
    "\n",
    "# Key = ID, Value = Publications Name\n",
    "dataset_group_dict = dict()\n",
    "for row in open_dataset_group:\n",
    "    split_row =  row.split(\"\\t\")\n",
    "    \n",
    "    if split_row[1] == '':\n",
    "        continue\n",
    "    \n",
    "    if '\\n' in split_row[len(split_row)-1]:\n",
    "        split_row[len(split_row)-1] = split_row[len(split_row)-1].rstrip()\n",
    "        \n",
    "    dataset_group_id = split_row[0]\n",
    "    \n",
    "    count = 0\n",
    "    field_list = list()\n",
    "    while count < 3:\n",
    "        if split_row[count] != '':\n",
    "            field_value = split_row[count]\n",
    "            if '\"' in field_value:\n",
    "                field_value = field_value.replace('\"', '')\n",
    "            field_list.append(field_value)\n",
    "        else:\n",
    "            field_list.append(\"NULL\")\n",
    "        count += 1\n",
    "    \n",
    "    dataset_group_dict[dataset_group_id] = field_list\n",
    "\n",
    "open_dataset_group.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0acf14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginInsert('dataset_group')\n",
    "fillTable(dataset_group_dict, open_sql)\n",
    "TableOutput('dataset_group', dataset_group_dict, schema_dict['dataset_group'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0579050b",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write dataset_pair_visualization Schema Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0979c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('dataset_pair_visualization', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8eca4c",
   "metadata": {},
   "source": [
    "### Insert values dataset_pair_visualization into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0368c675",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id_list = list()\n",
    "for key, item in dataset_dict.items():\n",
    "    dataset_id_list.append(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7445aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractHarComTwo(begin, end, compare_list, field_one, field_two):\n",
    "    # Create Gene Dictionary\n",
    "    gen_dict = dict() # Key: ID, Value: List of field\n",
    "    \n",
    "    # Extract information from Harmonizome.sql\n",
    "    begin = begin\n",
    "    end = end + 1\n",
    "\n",
    "    length = end - begin\n",
    "    id_index = 0\n",
    "    with open('harmonizome.sql', 'r') as f:\n",
    "        count = 0\n",
    "        for line in itertools.islice(f, begin-1, end):\n",
    "            line = str(line)\n",
    "            if count == length:\n",
    "                print(line)\n",
    "                break\n",
    "            count += 1\n",
    "            quote = False\n",
    "            slash = False\n",
    "\n",
    "            row = line.rstrip()\n",
    "            if row[0] == '(':\n",
    "                final_str = ''\n",
    "                for i in row:\n",
    "                    if i == \"'\" and quote == False:\n",
    "                        quote = True\n",
    "                    elif slash == True:\n",
    "                        slash = False\n",
    "                    elif \"\\\\\" == i and quote == True:\n",
    "                        slash = True\n",
    "                    elif i == \"'\" and quote == True:\n",
    "                        quote = False\n",
    "                    elif quote == True:\n",
    "                        if \",\" in i:\n",
    "                            final_str += '*'\n",
    "                        else:\n",
    "                            final_str += i\n",
    "                    else:\n",
    "                        final_str += i\n",
    "                final_str = final_str.replace(\"'\", \"\")\n",
    "                final_str = final_str[1:-2]\n",
    "                split_list = final_str.split(',')\n",
    "                \n",
    "                dataset_one = split_list[field_one]\n",
    "                dataset_two = split_list[field_two]\n",
    "                \n",
    "                identifier = split_list[0]\n",
    "\n",
    "                if dataset_one in compare_list and dataset_two in compare_list:\n",
    "                    row_list = list()\n",
    "\n",
    "                    for value in split_list:\n",
    "                        if '*' in value:\n",
    "                            row_list.append(value.replace(\"*\", \",\"))\n",
    "                        else:\n",
    "                            row_list.append(value)\n",
    "\n",
    "                    gen_dict[identifier] = row_list\n",
    "\n",
    "                id_index = split_list[0]\n",
    "    return(gen_dict, id_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9416df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pair_visualization_dict, index_idx = extractHarComTwo(71897222, 71900875, dataset_id_list, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f0dafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginInsert('dataset_pair_visualization')\n",
    "fillTable(dataset_pair_visualization_dict, open_sql)\n",
    "TableOutput('dataset_pair_visualization', dataset_pair_visualization_dict, schema_dict['dataset_pair_visualization'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96efdb7",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write dataset_visualization Schema Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f8f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('dataset_visualization', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32c1507",
   "metadata": {},
   "source": [
    "### Insert values dataset_visualization into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dad6a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_visualization_dict, index_idx = extractHarCom(71901076, 71901403, dataset_id_list, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b6987",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginInsert('dataset_visualization')\n",
    "fillTable(dataset_visualization_dict, open_sql)\n",
    "TableOutput('dataset_visualization', dataset_visualization_dict, schema_dict['dataset_visualization'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b11f5e0",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write dataset_test Schema Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99314da",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('dataset_test', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82857a95",
   "metadata": {},
   "source": [
    "### Insert values dataset_test into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b761186",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_dict, index_idx = extractHarCom(71900936, 71901047, dataset_id_list, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcb1c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginInsert('dataset_test')\n",
    "fillTable(dataset_test_dict, open_sql)\n",
    "TableOutput('dataset_test', dataset_test_dict, schema_dict['dataset_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31a710a",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write devi_report Schema Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d800d3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('devi_report', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1fc039",
   "metadata": {},
   "source": [
    "### Insert values devi_report into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geneset_list - Attribute names\n",
    "devi_report_dict, index_idx = extractHarCom(71901630, 71904444, geneset_list, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3745e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginInsert('devi_report')\n",
    "fillTable(devi_report_dict, open_sql)\n",
    "TableOutput('devi_report', devi_report_dict, schema_dict['devi_report'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e0577e",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write user_search Schema Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd812eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('user_search', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b68a281",
   "metadata": {},
   "source": [
    "### Insert values user_search into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c954dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_search_dict, index_idx = extractHarAll(72921456, 73266718)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8337da12",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginInsert('user_search')\n",
    "fillTable(user_search_dict, open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a126c83",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write download Schema Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d8e2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('download', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ec64f0",
   "metadata": {},
   "source": [
    "### Insert values download into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31500b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dict, index_idx = extractHarCom(71904476, 71905659, dataset_id_list, 2)\n",
    "\n",
    "beginInsert('download')\n",
    "fillTable(download_dict, open_sql)\n",
    "TableOutput('download', download_dict, schema_dict['download'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff06dde",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write download_type Schema Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3b2800",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('download_type', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41d933b",
   "metadata": {},
   "source": [
    "### Insert values download_type into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359cf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_type_dict, index_idx = extractHarAll(71906805, 71906822)\n",
    "\n",
    "beginInsert('download_type')\n",
    "fillTable(download_type_dict, open_sql)\n",
    "TableOutput('download_type', download_type_dict, schema_dict['download_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1c07b4",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write measurement Schema Table into master SQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639630c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('measurement', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41677fd",
   "metadata": {},
   "source": [
    "### Insert measurement into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49b1cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_dict, index_idx = extractHarAll(72410301, 72410329)\n",
    "\n",
    "beginInsert('measurement')\n",
    "fillTable(measurement_dict, open_sql)\n",
    "TableOutput('measurement', measurement_dict, schema_dict['measurement'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e361ef",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write naming_authority Schema Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f937766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('naming_authority', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dda8b7",
   "metadata": {},
   "source": [
    "### Insert naming_authority into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba06250",
   "metadata": {},
   "outputs": [],
   "source": [
    "naming_authority_dict, index_idx = extractHarAll(72901318, 72901409)\n",
    "\n",
    "beginInsert('naming_authority')\n",
    "fillTable(naming_authority_dict, open_sql)\n",
    "TableOutput('naming_authority', naming_authority_dict, schema_dict['naming_authority'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38087fdd",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write hgnc_root_family Schema Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cfbf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('hgnc_root_family', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03039665",
   "metadata": {},
   "source": [
    "### Insert hgnc_root_family and hgnc_root_families_to_genes into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c16110",
   "metadata": {},
   "outputs": [],
   "source": [
    "hgnc_root_family_dict, index_idx_hgnc_root = extractHarAll(72382327, 72382635)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4361cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "hgnc_root_families_to_genes_dict, index_idx_hgnc_genes = extractHarCom(72364694, 72382298, gene_id_list, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21411c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key: Group Name, Value: entry in list form\n",
    "temp_hgnc_root_family_dict = dict()\n",
    "for key, value in hgnc_root_family_dict.items():\n",
    "    temp_hgnc_root_family_dict[value[1]] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b56a8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(temp_hgnc_root_family_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a792e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key: gene symbol, Value: [gene_fk, gene_symbol]\n",
    "# gene_group_map_dict = {'H1-6': ['1935', 'H1 histones']}\n",
    "\n",
    "gene_group_map_dict = pickle.load(open(\"gene_group_map_dict.pkl\", \"rb\"))\n",
    "\n",
    "for key, value in gene_group_map_dict.items():\n",
    "    if value[0] != \"\" and value[1] != \"\":\n",
    "        if value[1] not in temp_hgnc_root_family_dict.keys():\n",
    "            hgnc_url = \"https://www.genenames.org/data/genegroup/#!/group/{}\".format(value[0])\n",
    "            index_idx_hgnc_root = int(index_idx_hgnc_root) + 1\n",
    "            hgnc_root_family_dict[value[1]] = [index_idx_hgnc_root, value[1], value[0], hgnc_url]\n",
    "\n",
    "pprint.pprint(hgnc_root_family_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b35f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "genegroupname_to_hgnc_root_family_fk_dict = dict()\n",
    "for key, value in hgnc_root_family_dict.items():\n",
    "    genegroupname_to_hgnc_root_family_fk_dict[value[1]] = value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647cba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(genegroupname_to_hgnc_root_family_fk_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3bf53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(gene_group_map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f72d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "genesymbol_to_gene_fk_dict = dict()\n",
    "for key, value in gene_dict.items():\n",
    "    genesymbol_to_gene_fk_dict[value[1]] = value[0]\n",
    "pprint.pprint(genesymbol_to_gene_fk_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c7bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gene, value in gene_group_map_dict.items():\n",
    "    if value[0] != \"\" and value[1] != \"\":\n",
    "        if gene in genesymbol_to_gene_fk_dict.items():\n",
    "            gene_fk = genesymbol_to_gene_fk_dict[gene]  \n",
    "            if gene_fk not in temp_hgnc_root_family_dict.keys():\n",
    "                index_idx_hgnc_genes = int(index_idx_hgnc_genes) + 1\n",
    "                entry_list = [index_idx_hgnc_genes, gene_fk, genegroupname_to_hgnc_root_family_fk_dict[value[1]]]\n",
    "                hgnc_root_families_to_genes_dict[index_idx_hgnc_genes] = entry_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b79bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginInsert('hgnc_root_family')\n",
    "fillTable(hgnc_root_family_dict, open_sql)\n",
    "TableOutput('hgnc_root_family', hgnc_root_family_dict, schema_dict['hgnc_root_family'])\n",
    "\n",
    "open_sql.write(\"\\n\")\n",
    "printSchema('hgnc_root_families_to_genes', open_sql)\n",
    "\n",
    "beginInsert('hgnc_root_families_to_genes')\n",
    "fillTable(hgnc_root_families_to_genes_dict, open_sql)\n",
    "TableOutput('hgnc_root_families_to_genes', hgnc_root_families_to_genes_dict, schema_dict['hgnc_root_families_to_genes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264c3efd",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write stats Schema Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ccb1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09580509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21b0286e",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write stats mp_prediction Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe407de",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('mp_prediction', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08daa9d",
   "metadata": {},
   "source": [
    "### Insert mp_prediction into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8931a253",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_prediction_dict, index_idx = extractHarCom(72410370, 72901289, gene_id_list, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860a1c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginInsert('mp_prediction')\n",
    "fillTable(mp_prediction_dict, open_sql)\n",
    "TableOutput('mp_prediction', mp_prediction_dict, schema_dict['mp_prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecae333",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write idg_tdl_class Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21152da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('idg_tdl_class', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8455967e",
   "metadata": {},
   "source": [
    "### Insert idg_tdl_class into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709093c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "idg_tdl_class_dict, index_idx = extractHarAll(72384605, 72384610)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03936c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginInsert('idg_tdl_class')\n",
    "fillTable(idg_tdl_class_dict, open_sql)\n",
    "TableOutput('idg_tdl_class', idg_tdl_class_dict, schema_dict['idg_tdl_class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f9a133",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write idg_family Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e352a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('idg_family', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49f84e3",
   "metadata": {},
   "source": [
    "### Insert idg_family into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d9d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "idg_family_dict, index_idx = extractHarAll(72384576, 72384579)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18370bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginInsert('idg_family')\n",
    "fillTable(idg_family_dict, open_sql)\n",
    "TableOutput('idg_family', idg_family_dict, schema_dict['idg_family'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a21e47",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write ks_prediction Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1fb4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('ks_prediction', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045c7ee6",
   "metadata": {},
   "source": [
    "### Insert ks_prediction into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692b295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_prediction_dict, index_idx = extractHarAll(72384653, 72410275)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99cb41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginInsert('ks_prediction')\n",
    "fillTable(ks_prediction_dict, open_sql)\n",
    "TableOutput('ks_prediction', ks_prediction_dict, schema_dict['ks_prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee80d738",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------\n",
    "### Write ic_prediction Table into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25168d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.write(\"\\n\")\n",
    "printSchema('ic_prediction', open_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdaa2a0",
   "metadata": {},
   "source": [
    "### Insert ic_prediction into master SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaaa86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_prediction_dict, index_idx = extractHarCom(72382682, 72384550, gene_id_list, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b4f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "beginInsert('ic_prediction')\n",
    "fillTable(ic_prediction_dict, open_sql)\n",
    "TableOutput('ic_prediction', ic_prediction_dict, schema_dict['ic_prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3329ce61",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9d0ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_sql.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7db8ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcee07bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a57900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dca609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
